<a name="readme-top"></a>

<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href="#about-the-project">About this project</a></li>
    <li><a href="#data_used">Data used</a></li>
    <li><a href="#built-with">Used libraries</a></li>
    <li><a href="#applications">Applications</a></li>
  </ol>
</details>


<a name="about-the-project"></a>
## About this project

Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worlwide. The purpose of this work is to review the current state of the use of popular gradient boosting machine learning algorithms in predicting death from heart failure, and to highlight the potential benefits and challenges of implementing these algorithms.
<p align="right">(<a href="#readme-top">back to top</a>)</p>


<a name="data_used"></a>
### Data used

Data provided in the public domain by Kaggle.com:
[[CLICK HERE]](https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data) |
<p align="right">(<a href="#readme-top">back to top</a>)</p>


<a name="built-with"></a>
### Used libraries

- Pandas
- NumPy
- Matplotlib
- Sklearn
- LightGBM
- CatBoost
<p align="right">(<a href="#readme-top">back to top</a>)</p>


<a name="applications"></a>
### Applications

This is a reference-only work about gradient boosting algorithms, I'm sure it could be done much better with the intent of achieving best F1 and overall performance.
<p align="right">(<a href="#readme-top">back to top</a>)</p>
